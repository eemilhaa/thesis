% TODO add tech / software table?
\section{Materials and methods}

\subsection{Study design}

The study had two main goals.
Firstly, I aimed to develop a map interface for
interactively presenting an extensive spatial dataset on travel times,
and through the development process assess
the tools and options available for making such a map.
More precisely,
I focused on the choice of web mapping library
and on the different methods in preprocessing the mapped data.
The goal was to find how,
and to what extent,
these factors affect the map interface.
The second goal was to understand how map users utilize such a map interface,
and how the interactive map works as a representation.
Here I employed a survey to find out how
people use the map when given different tasks to complete with it,
and whether a highly interactive presentation approach affects
how map users perceive the mapped phenomenon and interpret the map.
These two themes, the development process and the survey,
make up the two high-level components of the study.

% While the primary goal of the development process was
% to produce the map presentation and enable the survey,
% the development process in and of itself was crucial to the study as well.
% Its purpose was to be the framework that
% allows for answering the research questions
% about the more technology-centric aspects of
% the making of an interactive map.

Pragmatically speaking, a large part of this study was
a software development project to produce a functional web map application,
and the parts that were not, were still reliant on
the software development project succeeding.
This naturally affected the study design.
It allowed for freedom in crafting a map interface made exactly for this study,
but also introduced limitations
as any functionality to be included in the map, and in the study,
had to also be implemented.
In other words, the technical implementation as well as the survey
had to be designed around what is meaningful to study,
but also based on what is realistic to implement.
To minimize the risk and uncertainty inherent to such a setting,
I utilized modern software development methodologies
\parencite{mar2009, saq2020, bec2001, sha2017, kuh2017}
in planning the development process and the study as a whole.
Based on these,
I formatted the following points of focus
to guide the development process:
\begin{itemize}
	\item Plan minimally and adapt the plan constantly.
	\item Prioritize a working state of the entire application over details in single components.
	\item Adapt to technical constraints at the start, not at the end.
\end{itemize}

By adhering to these principles I could at an early stage see
whether the study was realistic, and,
especially considering the more technology-centric side of the study,
hone in on what research questions were actually meaningful.
Iteratively improving the application as a functional whole
allowed me to consider the map interface
from the perspective of the map user as early as possible,
better integrating the survey into the study.
This is important as the map presentation is simultaneously an output of the development process
and an input to the design of the survey.

For an overview of the study design see figure \ref{fig:study design}.
% This allowed me to improve the relevancy of my research. TODO Discussion?
% I say this not only in the context of gaining valuable results to my research questions --
% I want to emphasize that to even know what research questions to ask is impossible with a linear approach.

% While the development process and the survey were linked to each other,
% they each had their separate goals and outputs too.
% In addition to producing the map presentation,
% the development process had to enable testing and answering my research questions
% about the making of an interactive map.
% This placed increased
% The goal of the survey is to gain insight on
% how the interactive map works as a representation of the mapped phenomenon.
% With the survey I collect data on map usage,
% which I in turn analyse to answer my research questions related to the map usage.

\begin{figure}[H]
	\centering
	\includegraphics[width=\diagramwidth]{visual/figures/diagrams/study_design.png}
	\caption{An overview of the study design.}
	\label{fig:study design}
\end{figure}


\subsection{Helsinki region Travel Time Matrix}

The \acrlong{ttm} (\acrshort{ttm}) \parencite{fin2023}
is a dataset containing information of travel times and distances
in the Helsinki region in southern Finland.
This dataset was crucial to developing the map application,
as it was the sole source of the travel times shown on the map.
The dataset and the set of methods with which it is produced are open-source.

% Describe ttm in general: ykr, origin dest pairs etc (more surface level stuff common to all matrices)
A significant component of the \acrshort{ttm} is the \acrlong{ykr} (\acrshort{ykr})
statistical grid made by the Finnish Environmental Institute.
The grid has a spatial resolution of 250x250m, and it covers the entire Finland.
Most importantly, however, the part of the \acrshort{ykr} grid that overlaps with
the Helsinki region provides the spatial component for
the travel times stored in the \acrshort{ttm}.
The spatial extent of the dataset is shown in figure \ref{fig:ttm extent}.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{visual/figures/ttm/ttm_extent}
	\caption{The location and extent of the TTM}
	\label{fig:ttm extent}
\end{figure}

The \acrshort{ttm} stores the travel times and distances
from every \acrshort{ykr} grid cell to every other  \acrshort{ykr} grid cell
within the Helsinki region.
The Helsinki region fits 13231 \acrshort{ykr} grid cells,
which means that the complete \acrshort{ttm} contains travel times and distances for
over 175 million routes.

All the routes are calculated for multiple different travel modes.
The primary travel modes are walking, cycling, public transportation and private car,
and, when applicable, each mode has variations based on
time of day and / or walking or cycling speed.
The time of day is especially relevant to motorized transport
in the form of the rush hour, for example,
while walking speed affects any travel mode
where a significant portion of the trip is covered on foot.
To be comparable with each other,
the travel times for all travel modes are
calculated with a \textit{door-to-door approach}
which accounts for things such as walking to a bus stop,
waiting for transfer times based on public transit schedules,
or locking and unlocking a bike \parencite{ten2020}.

% Describe the particular matrix (2023), methodology etc
\acrshort{ttm}s have been calculated for multiple years.
Differences between these datasets exist in the applied methodologies
and, thus, also in the content \parencite{ten2020}.
Also, the underlying city structure as well as the street and public transport networks
are by no means static over the years
which further introduces differences.
The map presentation I developed in this study
is based on the 2023 version of the \acrshort{ttm},
the newest one at the time of writing.
See table \ref{tab:ttm description} for an overview of the dataset,
and table \ref{tab:ttm table structure} for all the travel modes and
their variations included in the dataset.

\input{visual/tables/ttm_description.tex}

\input{visual/tables/ttm_table_structure.tex}



\subsection{Implementation of the map presentation}

\subsubsection{Software requirements}
\label{sec:software req}

Software requirements are the functionalities and properties
that a given system should have,
as well as the constraints it must adhere to \parencite{chu2009}.
They are an essential aspect to consider in software development
as they are a way to explicate
what is being developed and what exactly is the framework
in which an implementation process is carried out \parencite{saq2020}.
Software requirements are often divided into
functional and nonfunctional requirements.
Functional requirements define the user-facing features of the system
while nonfunctional requirements describe the properties of a system
\parencite{chu2009}.
Nonfunctional requirements can be further divided into
quality attributes and constraints.
Quality attributes describe \textit{how} the software should be,
while constraints most often refer to technical limitations \parencite{chu2009}.

The starting point for specifying the requirements of the map application
was the decision to prioritize real-time interaction over minute detail in the map interface.
The goal of the map interface was to act as a dynamic overview to the entire \acrshort{ttm}.
As mentioned in the previous section,
the spatial dimension of the \acrshort{ttm} is large.
If all of it is to be explored,
an interaction exchange to select and re-select different locations to map
should be as effortless and instantaneous as possible.
The other dimension, travel mode, is much smaller,
but should also be interactively selectable.
These two goals, while still quite vague,
immediately placed a number of requirements on the application.
From the perspective of the user,
there must be functionalities for interacting with the map to
select different locations, preferably very rapidly,
and for selecting different travel modes.
A significant quality attribute to consider is that the application should
be responsive enough for instantaneous real-time interactivity.

From a technology-centric perspective an essential factor was
the decision to target the web as the platform.
This constraint was the starting point for considering the technologies
of the implementation.
From an architectural standpoint,
it meant that the application is more specifically a \textit{web application}
consisting of a frontend (a map interface) and a backend
(a solution for getting data to the map interface running on the client).
The high interactivity necessitates a \acrshort{spa} design in the frontend.
In further references to an \textit{application},
I mean the functional whole made of a map interface (frontend) and data access (backend)
\parenfig{web map app}.

\begin{figure}[H]
	\centering
	\includegraphics[width=\diagramwidth]{visual/figures/diagrams/web_map_app}
	\caption{
		A web map application like the one described above requires
		a frontend for providing the map interface
		and a backend for supplying the frontend with data to map.
	}
	\label{fig:web map app}
\end{figure}

I specified the software requirements at this quite non-detailed
level at first.
In accordance with the guideline of continuous adaptation \parencite{bec2001, mar2009},
I further focused them only as the application and the study took shape.
However, to communicate the development and study process in an orderly manner,
and to motivate the design decisions I've made,
I present the requirements of the final application here.
Still, I should emphasize that the reality is not this linear.

The functional requirements specify the styles and modes of interaction,
as well as the set of operations a user can carry out with the map.
Firstly, the map should have two modes of interaction for selecting locations to be mapped,
both carried out as direct manipulation of the map.
These include clicking the map with a pointing device to \enquote{lock} the map on the clicked location,
and continuously changing the mapped location by moving the cursor over the map
(referred to as \textit{hovering}).
This enables comparing two different modes of interaction in the study:
a \textit{locked mode}, i.e. producing a static map by clicking,
and a \textit{hovering mode}, i.e. producing
a highly dynamic, live,
representation of the accessibility under the cursor.
There should also be interface capabilities for selecting travel modes
and changing the mode of interaction.
To facilitate the exploration of the mapped area
at different points of focus and levels of detail,
the map should support panning and zooming the view.
The functional requirements are documented in table \ref{tab:functional requirements}.

\input{visual/tables/functional_requirements.tex}

For the quality attributes of the application,
performance is an essential consideration --
both in the sense of software performance
and the responsiveness of the application as perceived by the user.
The most important consideration here is
the aforementioned hovering mode:
Real-time interaction by hovering the mouse above the map
can mean tens of data requests and map renders
per second.
This must be considered in both the front and backend of the application.
Quality attributes that are invisible to a user, but still vital,
are that the application can be maintained and deployed,
and that it can meet different real-world usage loads.
If these attributes were lacking,
the application would have little real value.
The \textit{deployment environment},
in other words the computing platform onto which the server-side of the application is deployed,
is the container orchestration platform \textit{Rahti} provided by the \presentacr{csc}.
Rahti is based on the \textit{OpenShift} platform,
which in turn runs on \textit{Kubernetes}.
Kubernetes is a container orchestration tool
that allows for declaratively managing clusters
of containerized applications and their accompanying services.
I mention these details because to the application they are constraints:
Both the front and backend implementations should be completely containerized,
and they both are deployed with the OpenShift flavour of Kubernetes.
Also, as is clear by now,
the frontend of the application is constrained to running in a web browser.
For the nonfunctional requirements of the application,
see table \ref{tab:nonfunctional requirements}.

\input{visual/tables/nonfunctional_requirements}


\subsubsection{Assessing data preprocessing methods and preprocessing the TTM}

\label{sec:preprocessing}
% The need for preprocessing
% - what would raw data be like?
% - why as much as possible should be precalculated
% && the requirements preprocessing must satisfy
With initial testing,
it became obvious that
visualizing unprocessed \acrshort{ttm} data,
i.e. the complete 13000-cell grid of travel times for every location,
was not an option. This was due to the
unresponsiveness of the map interface.
Based on this, coupled with the characteristics of the TTM data,
I formed the hypothesis that either the file sizes
or the geometrical complexity of the data were
the major factor limiting the responsiveness of the map,
i.e. the performance bottleneck.

So it was clear that
some type of preprocessing as well as simplification of the 
\acrshort{ttm} data was necessary --
both to test the hypothesis and to enable real-time interaction in the map.
The goal of assessing different methods of data preprocessing, thus,
was to first find the suitable methods and levels of preprocessing and simplifying the data,
and then to compare the effectiveness of different methods.

When assessing the preprocessing methods, I focused on:
\begin{itemize}
	\item The impact on the responsiveness of the map interface when mapping the data.
	\item The impact on the amount of information on the map,
	i.e. how much visual information is lost when a given method is applied.
\end{itemize}

I assessed four methods of preprocessing the data:
\begin{itemize}
	\item Aggregation of travel time data into isochrone polygons.
	\item Limiting the maximum travel time, i.e. the geographical extent of the results.
	\item Reducing the coordinate precision of geometries.
	\item Minimizing files (simplifying GeoJSON structure, compression using gzip).
\end{itemize}

Out of these methods, isochrone aggregation and travel time limitation reduced
the geometrical complexity of the data, i.e reduced the amount of polygons needed to render the map:
They either dissolved multiple grid cells into larger polygons \parenfig{isochrone intervals},
or removed data by discarding geometries based on travel-time values \parenfig{tt limits}.
Of course, as a result, the file sizes were affected as well.
Reducing coordinate precision or minimizing files did not affect the number or extent of geometries
(unless coordinate precision were limited to an extreme).
In this sense, these methods did not alter the geometrical complexity of the data,
solely reducing the file sizes.

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.5\textwidth}
		\includegraphics[width=\textwidth]{visual/figures/ttm/isochrone_interval_1}
		\caption{No isochrones}
		\label{fig:interval 1}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[b]{0.5\textwidth}
		\includegraphics[width=\textwidth]{visual/figures/ttm/isochrone_interval_5}
		\caption{Isochrone interval = 5 minutes}
		\label{fig:interval 10}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[b]{0.5\textwidth}
		\includegraphics[width=\textwidth]{visual/figures/ttm/isochrone_interval_15}
		\caption{Isochrone interval = 15 minutes}
		\label{fig:interval 15}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[b]{0.5\textwidth}
		\includegraphics[width=\textwidth]{visual/figures/ttm/isochrone_interval_30}
		\caption{Isochrone interval = 30 minutes}
		\label{fig:interval 30}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{visual/figures/ttm/isochrone_cbar}
	\end{subfigure}%
	\caption{
		Travel time central to central Helsinki by public transport.
		Different levels of simplification can be achieved by
		aggregating travel times into isochrone polygons.
		Four examples are shown here, from no simplification
		to a highly simplified presentation
		(\ref{fig:interval 1}--\ref{fig:interval 30}).
	}
	\label{fig:isochrone intervals}
\end{figure}

\begin{figure}[H]
	\centering
	\begin{subfigure}[b]{0.5\textwidth}
		\includegraphics[width=\textwidth]{visual/figures/ttm/tt_limit_walk}
		\caption{Walk, 60-minute limit}
		\label{fig:limit walk}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[b]{0.5\textwidth}
		\includegraphics[width=\textwidth]{visual/figures/ttm/tt_limit_bike}
		\caption{Bike, 60-minute limit}
		\label{fig:limit bike}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[b]{0.5\textwidth}
		\includegraphics[width=\textwidth]{visual/figures/ttm/tt_limit_pt}
		\caption{Public transport, 60-minute limit}
		\label{fig:limit pt}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[b]{0.5\textwidth}
		\includegraphics[width=\textwidth]{visual/figures/ttm/tt_limit_car}
		\caption{Car, 60-minute limit}
		\label{fig:limit car}
	\end{subfigure}%
	\hfill
	\begin{subfigure}[b]{0.55\textwidth}
		\includegraphics[width=\textwidth]{visual/figures/ttm/tt_limit_legend}
	\end{subfigure}%
	\caption{
		The area where central Helsinki is reachable within an hour of travel.
		In general, limiting the maximum travel time reduces the spatial extent of data,
		more drastically for walking and biking (\ref{fig:limit walk}--\ref{fig:limit bike}),
		and less so for public transport and car (\ref{fig:limit pt}--\ref{fig:limit car}).
	}
	\label{fig:tt limits}
\end{figure}

To enable the assessment
I constructed a modular preprocessing pipeline
(figure \ref{fig:preprocessing}).
By modular I mean that,
while the complete pipeline applies all preprocessing methods,
the design allows for isolated testing of the
different components of the pipeline, with different parameters.
I used Python \parencite{python} for implementing most of the preprocessing pipeline,
relying on the GeoPandas \parencite{jor2024} library for all spatial operations.
In addition, I carried out file compression with
the standard GNU utilities bash \parencite{bash} and gzip \parencite{gzip}.
Gzip compression was the natural choice,
as it is the ubiquitous approach to file compression on the web. 
I tested the preprocessing methods on
a randomly picked set of 100 locations in the \acrshort{ttm},
for each travel mode.
A random sample of locations is necessary when either
isochrone aggregation or a travel time limitation is applied,
since in these cases the complexity of the resulting
data varies greatly based on location.

\begin{figure}[H]
	\centering
	\includegraphics[width=\diagramwidth]{visual/figures/diagrams/preprocessing.png}
	\caption{Preprocessing}
	\label{fig:preprocessing}
\end{figure}

To measure the effects on file sizes,
I calculated the mean combined file size of the all the files needed to represent
all the travel modes for a single cell in the dataset
when a given method has been applied.
I calculated these values as averages of a random sample as described above.

I assessed the impact the preprocessing methods have on the responsiveness of the map
by using the data with the finished map application.
The details of the map application are in the next section.
This assessment was qualitative,
as it was based on my own perception of responsiveness when using the map.
Quantitative testing of rendering speed would have been highly preferable,
but it proved to be difficult.
While many tools for profiling the rendering speed of web applications exist,
I did not succeed in two main areas
that would have been necessary for representative results.
I did not manage to limit the timing to strictly the map
component of the interface in such a way that
the test results would be reproducible.
I also did not find a way to automate a set of renders
on a sample of locations.
Averaging the renders of a single location would not suffice
due to the differences of data complexity between locations.
The tools I tried were the Firefox profiler \parencite{firefoxprofiler}
and the React developer tools browser extension \parencite{reactdevtools}
on the Firefox and Chromium web browsers. % TODO

I carried out the assessment of the loss of information in two ways:
Qualitatively for all methods by observing the processed data on the map,
and, in the case of limiting maximum travel time,
quantitatively by calculating the percentage of the total dataset area
that the processed data covers.
These percentages are, again, averages of a random sample as described above.

It must be noted that the effects of all preprocessing methods listed here
depend entirely on the parameters with which they are applied.
For example, a travel time limit of 1 minute would certainly enable
a responsive map, yet remove all information from the presentation.
Another consideration is that testing, assessing and reporting every possible combination
of all preprocessing methods and their parameters is simply unrealistic.
So, as briefly mentioned before, I carried out the assessment in two iterations:
The first was to find out the suitable parameters for each method,
the goal being to enable the functionalities required of the map application
\parentab{functional requirements}.
This part, being reliant on my perception and judgement,
was a highly qualitative process.
After finding the suitable parameters,
I assessed the effects of each preprocessing method,
as elaborated above.
This detailed assessment was done with the parameters found in the first part.

Appendix \ref{appendix:repositories} includes a link to the repository
containing the preprocessing pipeline.
The same repository also holds the quantitative tests described above
as an interactive Jupyter Notebook.


\subsubsection{Assessing web mapping libraries and implementing the frontend}

Considering this study,
the map interface is the most crucial component of the application.
It is the frontend that a user interacts with,
providing the \acrshort{ui} capabilities.
The web mapping library plays a key part in implementing the interface,
and in enabling the entire application.
In addition to rendering data correctly and efficiently,
the web mapping library needs to enable user-map interactions to be
captured and propagated to the underlying application.
The underlying application in this case, as mentioned in
section \ref{sec:software req},
is a web map application
that, in addition to mapping,
handles various modes of interaction,
\acrshort{http} requests and responses, and data access.
So, an interaction exchange with the map
must be able to alter application state outside the map.
For example,
clicking the map results in the fetching of new data from the backend,
as well as toggling the mode of interaction.

As mentioned in section \ref{sec:web maps},
managing state in web-applications can be complex.
Keeping in mind the requirements specified for this particular application
as well as the necessity of \acrshort{spa} design (section \ref{sec:software req}),
I considered a general-purpose \acrshort{ui} framework
essential to provide a robust way of controlling the state of the frontend.
Also, in general, using a framework instead of a self-made solution
means less room for error in the implementation,
and in, this sense, improves the reliability of results.
In this study I used React \parencite{react} as the \acrshort{ui} framework
for three reasons:
It is the framework I am most familiar with,
it is the most widely used and documented framework,
and also it is the only framework that
multiple web-mapping libraries have integration capabilities for.

With the above considerations in mind,
I based my assessment of web mapping libraries on three criteria:
\begin{itemize}
	\item Visual quality of the map
	\item Responsiveness of the map
	\item UI integration capabilities (tested only with React)
\end{itemize}

When selecting which web mapping libraries to assess,
I used three properties as a baseline.
The library should be licensed as \presentacr{foss},
It should be actively maintained,
and it should have capabilities to integrate to a general purpose UI framework.
As stated above, the third property meant, in practice, React.
With these considerations I arrived at three web mapping libraries:
Leaflet \parencite{leaflet}, Maplibre \parencite{maplibre} and Deck.gl \parencite{deckgl}.
More precisely, in the case of Maplibre I used the React Map GL wrapper
\parencite{reactmapgl} for integrating maplibre and react, and in the case of Leaflet
I used the React Leaflet wrapper \parencite{reactleaflet} for the same purpose.
When comparing these three libraries, it should be noted that
both Maplibre and Deck.gl have capabilities for \presentacr{gpu}-accelerated rendering.
Enabled by a web technology called WebGL, this means that much of the computational load
of rendering data is off-loaded to the \acrshort{gpu},
often times resulting in better rendering performance \parencite{ang2014, mia2017}.
Unlike Leaflet, Deck.gl and Maplibre also natively support vector base maps.

To assess the web mapping libraries,
I used each of them as the map interface of the frontend. % ref frontend fig here?
I implemented a feature-complete map interface using both
Deck.gl and Maplibre, but with Leaflet I stopped after very minimal testing
as it became clear that the library would not be used in the implementation due
to performance issues with React-Leaflet.
Upon further investigation, it would have been possible to
overcome these issues, at least to an extent,
by utilizing a lower-level, self-made,
solution to integrating Leaflet into React \parencite{gaj2023}.
However, I deemed that to be out-of-scope for this study.
I assessed the visual quality of the map qualitatively, and,
for the reasons I stated in section \ref{sec:preprocessing},
I had to resort to qualitative assessment
for assessing the responsiveness as well.
For assessing integration with React
I utilized online documentation of potential solutions,
as well as my development experience in implementing the frontend.

On a technical level,
simplicity and modularity were the main goals of the frontend implementation.
Simplicity meant including only the functionalities that would be absolutely necessary,
and modularity meant that any given component of the implementation
should be customizable without affecting the other components.
These two factors were a necessity for there to be
any level of comparability in the testing of different mapping libraries.
Considering the functionality of the map interface,
The UI component responsible for map rendering and interaction
only required access to the mapped data,
and a way to alter the mapped location.
Aside from these two aspects,
the map component along with its internal state was completely encapsulated
from the other components of the frontend application.
This meant that swapping the map library
required no changes to the application outside the map component.
In addition to the UI components,
only a single service for communicating with the backend was needed,
which I implemented with the Axios \acrshort{http} library \parencite{axios}.
To minimize my own errors in the implementation process,
I used TypeScript \parencite{typescript} as the language.
TypeScript transpiles to plain JavaScript,
but adds features such as strict typing to overcome JavaScript's known issues
when it comes to producing error-free and maintainable web applications \parencite{bie2014}.
See figure \ref{fig:frontend architecture} for the architecture of the frontend.

A link to the repository containing the source code
and further technical details of the frontend
can be found in appendix \ref{appendix:repositories}.

\begin{figure}[H]  % TODO location?
	\centering
	\includegraphics[width=\diagramwidth]{visual/figures/diagrams/frontend.png}
	\caption{
		The frontend architecture.
		The map component is responsible for map rendering and interaction
		as well as all map-specific state.
		All the additional, non-map, UI components are grouped together in this picture,
		as functionally they alter the application state in only one way.
	}
	\label{fig:frontend architecture}
\end{figure}

Simplicity was the goal in the UI of the frontend as well --
both to enable the comparable assessment of the map libraries,
and to act as a usable map interface in the survey.
UI components included the map and its control buttons (zoom, orientation),
a drop-down menu for selecting travel modes, and a legend.
Depending on mode of interaction,
a tooltip with travel time information was rendered under the cursor.
The content on the map included
a low-contrast base map designed for data visualization \parencite{cartopositron},
and translucent isochrone polygons rendered on top of it.
I utilized translucent overlay to
enable the comparison of the base map and the isochrone polygons,
as it is the comparison technique
often most intuitive for users when using interactive maps
\parencite{lob2015}.
To visualize the travel times of the isochrone polygons,
I applied colour to them, using the cividis colour map \parencite{nun2018}.
I chose this colour map since it is designed to enable accurate visual
interpretation of data through the perceptual uniformity of its colours,
combined with linearly increasing brightness \parencite{nun2018}.
Just as importantly, it is optimized to work equally well
for people with and without colour vision deficiencies \parencite{nun2018}.
For a visual overview of the map interface, see figure \ref{fig:frontend screenshot}.

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{visual/figures/screenshots/frontend.png}
	\caption{
		The UI of the map application.
		In addition to the map and its control buttons,
		there is a drop-down menu for selecting travel-modes, and a legend.
		Here, the map has been clicked to toggle the mode of interaction
		so that the map does not update with cursor movement.
		Instead, a tooltip with travel time information is displayed under the cursor.
	}
	\label{fig:frontend screenshot}
\end{figure}


\subsubsection{Application deployment and other technical infrastructure}

This section documents the additional steps and infrastructure
needed to enable and deploy the web map application as
a website accessible via the internet.
Firstly,
a backend was necessary for serving the preprocessed \acrshort{ttm} data
from the server-side to the client running the frontend.
The software requirements for the backend
(section \ref{sec:software req}) mean, in essence,
that the only functionality required of the backend
is to respond to requests with TTM data.
No business logic, state management or data manipulation is necessary.
From the perspective of the responsiveness of the application,
the backend should respond as quickly as possible.
Considering the above factors,
I implemented the backend
simply as an HTTP server serving TTM data as static files,
directly from the server-side filesystem.
The server software used was Nginx \parencite{nginx},
as it is specifically designed to be as performant and efficient as possible
\parencite{dej2020, ree2008}.
More feature-rich solutions, such as a database,
would have introduced unnecessary complexity
as well as computational overhead to the application.

In order to produce a deployable frontend application,
a frontend build tool was necessary.
I used Vite \parencite{vite} both as a development-time server
and for bundling the frontend application for production,
i.e. merging and minimizing the application code into
a single file optimized for browser execution.
To serve the bundled frontend, a server was necessary.
For similar reasons as with the backend,
I used Nginx \parencite{nginx} as the frontend server.

As detailed in section \ref{sec:software req},
the deployment environment for both the back- and frontend
servers was the OpenShift container orchestration platform.
So, in order to be deployed, both the front- and backend had to be containerized.
In short, containerization refers to a set of technologies
that enables packaging software and all its necessary components
into self-contained \textit{container images} that can be run as is,
regardless of the specifics of the underlying system \parencite{ben2022}.
I containerized the frontend by including the bundled
frontend application into an official Nginx container image.
The backend container was, again, an official Nginx image,
only with a custom configuration applied to serve TTM data as desired.
The data itself could not be included in the container due to file sizes.
Both the front- and backend container builds were automated with GitHub actions,
and the container images were hosted on GitHub container registry
to be easily accessible for the deployments.

The front- and backend were deployed separately.
I chose to use separate deployments to further decouple the components,
and to allow for easier scaling and maintenance as each deployment could be tweaked on its own.
Since both deployments were on the same platform,
much of the deployment specifics were identical between both components.
In the following, I will briefly introduce the structure of the deployments.
As the deployment tool was, in essence, Kubernetes,
some platform-specific terminology is used --
for further insight on the terms and concepts,
refer to the Kubernetes glossary \parencite{kubernetesglossary}.
Both deployments were based around a \textit{Deployment} object
running a set of \textit{replicated} server \textit{pods}.
A \textit{pod}, in this case,
was essentially a singular containerized server (either front- or backend).
In addition, a \textit{Service} object was needed to expose
the internal deployment network (on which the pods run),
and a \textit{Route} object was needed to route traffic from the internet to the Service.
As the single deviation from the above, the backend deployment also defined a
\textit{PersistentVolumeClaim} object for storing the TTM data.
This data volume was mounted to all replicated pods, granting them data access
without the need to duplicate data, even when scaling by replicating more pods.
Both deployments were defined declaratively with a Kubernetes manifest file.
For a visual high-level overview of the entire web map application deployment,
see figure \ref{fig:architechture}.
The deployment manifests for both the front- and backend are found in their respective repositories
\parenapp{repositories}.

\begin{figure}[H]
	\centering
	\includegraphics[width=\diagramwidth]{visual/figures/diagrams/architecture.png}
	\caption{
		In the deployment of the web map application,
		the front- and backend are managed separately.
		Once fetched from the server,
		the frontend runs on the client browser,
		handling all communication with the backend.
		The preprocessing of the TTM data is done beforehand, outside any deployments.
		Only the preprocessed data is uploaded to the server and made available to the
		backend server pods.
	}
	\label{fig:architechture}
\end{figure}


\subsection{Survey}

\subsubsection{Questionnaire design and structure}

I carried out a survey to
gather information on how map users utilize the map interface,
and how the interactive map works as a representation.
For this, I utilized an online questionnaire.  % TODO semi structured?
% I had three main reasons for using an online environment:
I chose to use an online environment,
as the map interface was also available on the web,
making it easier to answer the questionnaire and use the map simultaneously.
I constructed the questionnaire using the E-lomake platform
\parencite{elomake}.

The basis of the questionnaire design was to include
different tasks, or usage scenarios,
that the participant is prompted to complete by using the map interface.
After completing a task,
the participant answers questions relevant to how they carried out said task.
This task-question cycle can then be repeated to gain insight on the participant's
experience on completing various types of tasks.
Such questionnaire design is often referred to as \textit{task-based},
or \textit{scenario-based} design,
and is commonly used especially in \acrshort{hci} and \acrshort{ue} research
when studying user interaction with interfaces \parencite{ada2008, lew1991}.

Rather than specifying a particular target group,
I aimed for the questionnaire to be realistic to complete for as many as possible.
Following the generally approved guidelines,
or \enquote{conventional wisdom}, of questionnaire design \parencite{kro2018},
I kept the questionnaire and the task prompts and questions as short and direct as possible,
targetting a 10-15 minute total completion time for the whole questionnaire.
The question order was from most to least important to maximize
the value of responses where the participant does not finish the entire questionnaire.
I also paid attention to make the task prompts and questions
understandable without any previous knowledge of interactive maps or spatial accessibility.
The only explicit limitation I made was that the questionnaire should be completed
using a computer enabled with a pointing device such as a mouse or a touchpad.
This was to ensure all participants could utilize both modes of interaction in the map interface
(locked map and hovering).

Of course, the questionnaire was by no means totally inclusive in all other aspects.
As the map interface was a digital application reliant on computer graphics,
the questionnaire was essentially inaccessible to visually impaired people,
or to anyone without the needed capabilities for computer use.
Also, the questionnaire was in English only.

In the following, I present the questionnaire structure
and the purposes of the tasks and questions that I included.
A print of the entire questionnaire is found in appendix \ref{appendix:questionnaire}.

To present the questionnaire and the map interface,
I included a general descriptive text at the start.
The main goals here were to give an idea of the structure and extent of the survey,
explain how the map interface works,
and to provide instructions on how the questionnaire should be answered.
The questionnaire itself was divided into three main sections:
A task section where the participant carries out tasks with the map
and answers questions specific to those tasks,
a general section where the participant answers questions about
their general experience using the map,
and a backround / demographic information section
where the participant answers questions about themselves.
The questions were for the most part closed,
except for two open questions in the general section.

Task 1 prompted the user to observe the accessibility of
a single location as a static presentation,
including two questions about said location's accessibility.
I intentionally made both these questions very simple,
and made sure they have at least one answer option that is clearly right
and one that is clearly wrong.
This was to provide an opportunity for the participant to get accustomed to the map interface,
and to include questions that would work as control questions,
in other words, questions to ensure the validity and reliability of the responses.

Task 2 prompted the participant to compare
the accessibility of two locations
by alternating a static map view between them (i.e. locking the map on them).
The travel mode and amount of travel time were specified.
This task included a question to assess
which of these two locations is more accessible,
given the travel mode and time specification.
Task 3 repeated the same comparison but,
instead of locking the map to produce and examine static maps,
the participant was prompted to use the hovering mode on the two areas.
Like in task 2,
the question was again to assess which location is more accessible.
In addition,
I included a question about whether the assessment is easier or more difficult.
The purpose of these two tasks and their questions was
to find out if participants perceive the accessibility of
the same location differently depending on
the level of interactivity in the map presentation.

Task 4 was a loosely defined one, simply prompting the participant to
compare the accessibility of any two locations within the Helsinki region.
Afterwards, the participant was asked
which mode of interaction they used the most when accomplishing the task.
Task 5 prompted the user to observe how the accessibility changes
between the same two locations. Here, the question was the same as in task 4.
With these two tasks and their questions I aimed to find out
if the participants prefer different modes of interaction
in different types of usage scenarios.
In essence, task 4 calls for an observation of two point-like locations,
while in task 5 the participant is required to
observe a line-like area or set of many locations.

The general section included a question on
which map functionality the participants found most useful for exploring accessibility.
The answer options included both modes of interaction, and the travel mode selection.
In addition, an open text field was available for participants to define
other functionalities they found useful.
The purpose of this question was to gain information on the users preferences on using
the interactive map as a whole, and which functionalities they found most important.
Another general question was whether
the participants' general perception and understanding of accessibility
changed as a result of them interacting with the map.
This was a yes / no question with an open text field for further detailing the answer.
The purpose was to gain insight on if, and how, the participants considered the
interactive map impactful to understanding the mapped phenomenon.
As a final general question, participants were asked if they found the map
easy or difficult to use, again with a text field option for detailing the answer.
This question was intended to gain insight on the usability of the map interface.

The background section was included to gather information on the participants.
The questions were on the participants' familiarity with the topic of accessibility,
familiarity with the Helsinki geographical region, and familiarity with using interactive maps.
I also included a question on which modes of transport the participants use.
I used the responses to these questions in finding out if the participant characteristics
affected the answers to the other questions.
As the final two questions of the questionnaire,
I asked about the participants' gender and age group.
The purpose of these questions was to see how
different groups of people are represented in the sample of participants.


\subsubsection{Questionnaire distribution}

The distribution of the questionnaire happened mostly online.
Online locations for distribution included the student mailing list (e-mail)
of the geography department in the University of Helsinki,
and a Facebook group focused on urban planning discourse in the Helsinki region
\parencite{lisaakaupunkiahki}.

In addition, questionnaire distribution took place at a live workshop event hosted by the
Digital Geography Lab research group of the University of Helsinki.
Part of the larger European Researchers' Night event,
The workshop was held on the topic of urban accessibility and mobility,
and entry was granted free of charge to anyone interested.

The questionnaire was open to answers from 19.10.2023 to 30.11.2023.


\subsubsection{Participants}

The survey had a total of 31 participants.
19 of the participants identified as male,
10 as female and 2 preferred not to share their gender.
The age groups of the participants were late teens to young adults
(aged 15--35) (n=19) and adults (aged 35--64) (n=12).

Most of the participants were familiar with the topics of the questionnaire.
24 participants reported having previously seen accessibility visualizations,
while 7 participants had no experience of such maps.
22 participants rated themselves as being very familiar with the Helsinki region geographically,
9 somewhat familiar, and none rated themselves as being not at all familiar.
18 participants reported using interactive map applications daily,
7 weekly, and 5 monthly.

The participants consisted of users of all transport modes listed.
Within the previous week,
30 participants reported having walked, 15 biked, 27 used public transport
and 12 used car.

Appendix \ref{appendix:questionnaire responses}
includes plots of all questionnaire responses.


\subsubsection{Analysis of responses}

After the response period of the questionnaire was over,
I downloaded all gathered data and produced plots of how the responses were distributed
\parenapp{questionnaire responses}.
I did this in Python \parencite{python},
with the Pandas \parencite{pandas} and Matplotlib \parencite{hun2007}
libraries.

I analysed the responses to the closed questions visually based on the resulting plots.
To analyse the responses to the open questions,
I first read all the responses to familiarize myself with the data
and to identify any recurring themes.
After this, I categorized the responses based on these themes
and aggregated all responses by category.

To see whether the characteristics of the participants affected the responses,
I performed the analysis of the closed questions on subsets of the responses
based on the participants' background information.
However, it should be noted that this resulted in very small sample sizes.
For this reason I did not repeat such analysis for the open questions --
being optional, the open questions had much less responses to begin with,
and creating subsets based on participant characteristics resulted in too small sample sizes.
